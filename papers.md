### NPL

#### [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/pdf/1409.3215.pdf)
* [A Comparison of Sequence-to-Sequence Models for Speech Recognition](https://www.isca-speech.org/archive/Interspeech_2017/pdfs/0233.PDF)
* [Sequence to Sequence â€“ Video to Text](https://arxiv.org/pdf/1505.00487.pdf)




#### [Attention Is All You Need](https://arxiv.org/abs/1706.03762) 

* [Explain by Jay Alammar](http://jalammar.github.io/illustrated-transformer/) 
* [Tensor 2 Tensor Code for visualizating transformer](https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb)
* My own implementation

